{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOabwuHujkH1s2xYNeBFwM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khcolin/py-dl1/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "h7__GorKyRox",
        "outputId": "c4ada337-656c-45f2-dc60-74d6dfdc197c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a35a14517002>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#7-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load our data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "#7-1.\n",
        "# Load our data set\n",
        "x_train = np.array([10, 9, 3, 2])\n",
        "y_train = np.array([90, 80, 50, 30])\n",
        "\n",
        "def compute_mae(x, y, w, b):\n",
        "\n",
        "    m = x.shape[0]\n",
        "    cost = 0\n",
        "\n",
        "    for i in range(m):\n",
        "        f_wb =  w*x[i]+b          # 일차 회귀식 만들어보기\n",
        "        cost += abs( f_wb-y[i]       )  #MAE인 비용함수\n",
        "    total_mae = 1 / (m) * cost\n",
        "\n",
        "\n",
        "\n",
        "    return total_mae\n",
        "\n",
        "    compute_mae(x_train,y_train,6,30              )  #함수에 알맞은 인자 대입하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7-2.\n",
        "def compute_grad_new(x, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the gradient for new linear regression\n",
        "    Args:\n",
        "      x (ndarray (m,)): Data, m examples\n",
        "      y (ndarray (m,)): target values\n",
        "      w,b (scalar)    : model parameters\n",
        "    Returns\n",
        "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
        "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b\n",
        "     \"\"\"\n",
        "\n",
        "    # Number of training examples\n",
        "    m = x.shape[0]\n",
        "    dj_dw = 0\n",
        "    dj_db = 0\n",
        "    for i in range(m):\n",
        "        f_wb =  w*(x[i]**2+b)                #여기서 회귀식은?\n",
        "        dj_dw_i =  (f_wb-y[i]*(x[i]**2))             #미분 ?\n",
        "        dj_db_i =    (f_wb-y[i])           # 미분 (b에 대한)\n",
        "        dj_db += dj_db_i\n",
        "        dj_dw += dj_dw_i\n",
        "    dj_dw = dj_dw / m\n",
        "    dj_db = dj_db / m\n",
        "     return dj_dw, dj_db"
      ],
      "metadata": {
        "id": "8IUA3SyUyjwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7-3.\n",
        "#Function to calculate the cost\n",
        "def compute_cost(x, y, w, b):\n",
        "\n",
        "    m = x.shape[0]    #이 부분도 잘 생각해보세요.\n",
        "    cost = 0\n",
        "\n",
        "    for i in range(m):\n",
        "        f_wb = w * (x[i])**2 + b\n",
        "        cost +=  (f_wb-y[i])**2                     #cost 찾아보기\n",
        "    total_cost = 1 / (2 * m) * cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "G2Ji54aEysNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7-4.\n",
        "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n",
        "    \"\"\"\n",
        "    Performs gradient descent to fit w,b. Updates w,b by taking\n",
        "    num_iters gradient steps with learning rate alpha\n",
        "\n",
        "    Args:\n",
        "      x (ndarray (m,))  : Data, m examples\n",
        "      y (ndarray (m,))  : target values\n",
        "      w_in,b_in (scalar): initial values of model parameters\n",
        "      alpha (float):     Learning rate\n",
        "      num_iters (int):   number of iterations to run gradient descent\n",
        "      cost_function:     function to call to produce cost\n",
        "      gradient_function: function to call to produce gradient\n",
        "\n",
        "    Returns:\n",
        "      w (scalar): Updated value of parameter after running gradient descent\n",
        "      b (scalar): Updated value of parameter after running gradient descent\n",
        "      J_history (List): History of cost values\n",
        "      p_history (list): History of parameters [w,b]\n",
        "      \"\"\"\n",
        "\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    p_history = []\n",
        "    b = b_in\n",
        "    w = w_in\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        # Calculate the gradient and update the parameters using gradient_function\n",
        "        dj_dw, dj_db = gradient_function(x, y, w , b)\n",
        "\n",
        "        # Update Parameters using equation\n",
        "        b +=  -alpha*dj_db                    #들어갈 알맞은 코드는?\n",
        "        w +=   -alpha*dj_dw                   #들어갈 알맞은 코드는?\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            J_history.append( cost_function(x, y, w , b))\n",
        "            p_history.append([w,b])\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters/10) == 0:\n",
        "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
        "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
        "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
        "\n",
        "\n",
        "    return w, b, J_history, p_history #return w and J,w history for graphing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # initialize parameters\n",
        "w_init = 1\n",
        "b_init = 0\n",
        "# some gradient descent settings\n",
        "iterations = 100000\n",
        "tmp_alpha = 0.0004\n",
        "# run gradient descent\n",
        "w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha,\n",
        "                                                    iterations, compute_cost, compute_grad_new)\n",
        "#\n",
        "\n",
        "print(f\"(w,b) found by gradient descent: ({w_final:8.4f},{b_final:8.4f})\")"
      ],
      "metadata": {
        "id": "aCXVi57yyuv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7-5.\n",
        "print(f\"5 hours prediction {   w_final*5+b_final        :0.1f} scores\") #채우시오."
      ],
      "metadata": {
        "id": "qv3Do8RLy1hz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}